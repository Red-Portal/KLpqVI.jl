
\section{Pseudocodes}\label{section:pseudocode}
\subsection{Markov Chain Kernels}

  \begin{center}
\begin{minipage}[c]{0.63\textwidth}
  \begin{algorithm2e}[H]
    \DontPrintSemicolon
    \SetAlgoLined
    \KwIn{previous sample \(\vz_{t-1}\),
      previous parameter \(\vlambda_{t-1}\),
      number of proposals \(N\)
    }
    \(\vz^{(0)} = \vz_{t-1}\) \;
    \(\vz^{(i)} \sim q_{\text{def.}}\left(\vz;\vlambda_{t-1}\right)\quad\) for \(i = 1, 2,\ldots, N\) \;
    \(\widetilde{w}(\vz^{(i)}) = p(\vz^{(i)},\vx) \,/\, q_{\text{def.}}\left(\vz^{(i)}; \vlambda_{t-1}\right)\quad\) for \(i = 0, 1,\ldots, N\)\;
    \(\overline{w}^{(i)} = \frac{\widetilde{w}(\vz^{(i)})}{ \sum^{N}_{i=0} \widetilde{w}(\vz^{(i)}) }\quad\) for \(i = 0, 1,\ldots, N\)\;
    \(\vz_{t} \sim \mathrm{Multinomial}(\overline{w}^{(0)}, \overline{w}^{(1)}, \ldots, \overline{w}^{(N)}) \)\;
    \caption{Conditional Importance Sampling Kernel}
  \end{algorithm2e}
\end{minipage}
  \end{center}

  \begin{center}
\begin{minipage}[c]{0.62\textwidth}
  \begin{algorithm2e}[H]
    \DontPrintSemicolon
    \SetAlgoLined
    \KwIn{previous sample \(\vz_{t-1}\),
      previous parameter \(\vlambda_{t-1}\),
    }
    \(\vz^* \sim q_{\text{def.}}\left(\vz; \vlambda_{t-1}\right)\)\;
    \(\widetilde{w}(\vz) = p(\vz,\vx)/q_{\text{def.}}\left(\vz; \vlambda_{t-1}\right) \)\;
    \(\alpha = \min\left( \widetilde{w}\,(\vz^*)/\widetilde{w}\,(\vz_{t-1}), 1\right)\)\;
    \(u \sim \mathrm{Uniform}(0, 1) \)\;
    \eIf{u < \(\alpha\)}
        {
          %\(\vz_t \leftarrow \vz^*\)
          \(\vz_t = \vz^*\)
        }
        {
          %\(\vz_t \leftarrow \vz_{t-1}\)
          \(\vz_t = \vz_{t-1}\)
        }
        \caption{Independent Metropolis-Hastings Kernel}
  \end{algorithm2e}
\end{minipage}
  \end{center}

%% \subsection{Markov Chain Score Ascent Algorithms}

%% \begin{center}
%% \begin{minipage}[c]{0.6\textwidth}
%%   \centering
%%   \begin{algorithm2e}[H]
%%     \DontPrintSemicolon
%%     \SetAlgoLined
%%     \KwIn{MCMC kernel \(K_{\vlambda}(\vz,\cdot)\),
%%       initial sample \(\vz_0\),
%%       initial parameter \(\vlambda_0\),
%%       number of iterations \(T\),
%%       stepsize schedule \(\gamma_t\)}
%%     \For{\textcolor{black}{\(t = 1, 2, \ldots, T\)}}{
%%       \( \vz_{t} \sim K_{\vlambda_{t-1}}(\vz_{t-1}, \cdot) \)\;
%%       \( \vg\left(\vlambda\right) = -\vs\,(\vlambda; \vz_{t}) \)\;
%%       \( \vlambda_{t} = \vlambda_{t-1} - \gamma_t\, \vg\left(\vlambda_{t-1}\right) \)\;
%%     }
%%     \caption{Markovian Score Climbing}\label{alg:msc}
%%   \end{algorithm2e}
%% \end{minipage}
%% \end{center}

%%   \begin{center}
%%   \begin{minipage}[c]{0.63\textwidth}
%%     \begin{algorithm2e}[H]
%%       \DontPrintSemicolon
%%       \SetAlgoLined
%%       \KwIn{MCMC kernel \(K_{\vlambda}(\vz,\cdot)\),
%%         initial sample \(\vz_0^{(N)}\),
%%         initial parameter \(\vlambda_0\),
%%         number of iterations \(T\),
%%         stepsize schedule \(\gamma_t\)
%%       }
%%       \For{\(t = 1, 2, \ldots, T\)}{
%%         \(\vz_{t}^{(0)} = \vz_{t-1}^{(N)}\)\;
%%         \For{\(n = 1, 2, \ldots, N\)}{
%%           \(\vz_{t}^{(n)} \sim K_{\vlambda_{t-1}}(\vz_{t}^{(n-1)}, \cdot)\)\;
%%         }
%%         \( \vg\left(\vlambda\right) = -\frac{1}{N} \sum^{N}_{n=1} \vs\,(\vlambda; \vz_{t}^{(n)}) \)\;
%%         \( \vlambda_{t} = \vlambda_{t-1} - \gamma_t \, \vg\left(\vlambda_{t-1}\right) \,
%%         \)\;
%%       }
%%       \caption{Joint Stochastic Approximation}\label{alg:jsa}
%%     \end{algorithm2e}
%%   \end{minipage}
%%   \end{center}

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
