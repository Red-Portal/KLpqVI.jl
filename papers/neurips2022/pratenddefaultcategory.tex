
\prAtEndRestateii*
\label{proofsection:prAtEndii}\begin{proof}[Proof of \autoref{thm:prAtEndii}]\phantomsection\label{proof:prAtEndii}For notational convenience, we define the shorthand \begin {align*} \pi \left (\vz _{(1:N)}\right ) = \pi \left (\vz _1\right ) \, \pi \left (\vz _2\right ) \times \ldots \times \pi \left (\vz _N\right ). \end {align*} Then, \begin {alignat}{2} &\Esub {\Pi }{ f\left (\vlambda , \veta \right ) } \nonumber \\ &\quad = \int \left ( \frac {1}{N} \sum ^{N}_{n=1} \log q\left (\vz _n; \vlambda \right ) + \mathbb {H}\left [\,\pi \,\right ]\right ) \, \pi \left (\vz _{(1:N)}\right ) \, d\vz _{(1:N)} \nonumber \\ &\quad = \frac {1}{N} \sum ^{N}_{n=1} \left \{ \int \big (\, \log q\,(\,\vz _n; \vlambda \,) + \mathbb {H}\,[\,\pi \,] \,\big ) \, \pi \left (\vz _{(1:N)}\right ) \, d\vz _{(1:N)} \right \} &&\quad {\text {\textit {Swapped integral and sum}}} \nonumber \\ &\quad = \frac {1}{N} \sum ^{N}_{n=1} \int \big (\, \log q\,(\,\vz _n; \vlambda \,) + \mathbb {H}\,[\,\pi \,] \,\big ) \, \pi \left (\vz _n\right ) \, d\vz _{n} &&\quad {\text {\textit {Marginalized \(\vz _m\) for all \(m \neq n\)}}} \nonumber \\ &\quad = \frac {1}{N} \sum ^{N}_{n=1} \DKL {\pi }{q\left (\cdot ; \vlambda \right )} \nonumber &&\quad {\text {\textit {Definition of \(D_{\text {KL}}\)}}} \\ &\quad = \DKL {\pi }{q\left (\cdot ; \vlambda \right )}\label {eq:F_KL} \end {alignat} For \(\Esub {\Pi }{ g\left (\vlambda , \rvveta \right ) }\), note that \begin {align} \nabla _{\vlambda } f\left (\vlambda , \veta \right ) = \frac {1}{N} \sum ^{N}_{n=1} s\left (\vz _n; \vlambda \right ) = g\left (\vlambda , \veta \right ).\label {eq:F_grad_G} \end {align} Therefore, it suffices to show that \begin {align*} \nabla _{\vlambda } \DKL {\pi }{q\left (\cdot ; \vlambda \right )} &= \nabla _{\vlambda } \Esub {\Pi }{ f\left (\vlambda , \rvveta \right ) } &&\text {\textit {\cref {eq:F_KL}}} \\ &= \Esub {\Pi }{ \nabla _{\vlambda } f\left (\vlambda , \rvveta \right ) } &&\text {\textit {{Leibniz derivative rule}}} \\ &= \Esub {\Pi }{ g\left (\vlambda , \rvveta \right ) }. &&\text {\textit {\cref {eq:F_grad_G}}} \end {align*}\end{proof}
\begin{restatable}[]{lemma}{prAtEndRestateiii}\label{thm:prAtEndiii}\label {thm:additive} The bivariate function location and scale reparameterization function \( t\left (\vu , \vlambda \right ) = \mC \,\vu + \vm \) is additive with respect to \(\vlambda =\left [\mC , \vm \right ]\) such that \[ t\left (\vu , \alpha \,\vlambda + \beta \,\vmu \right ) = \alpha \,t\left (\vu , \vlambda \right ) + \beta \,t\left (\vu , \vmu \right ) \] for any \(\alpha \), \(\beta \).\end{restatable}
\label{proofsection:prAtEndiii}\begin{proof}[Proof of \autoref{thm:prAtEndiii}]\phantomsection\label{proof:prAtEndiii}Let us denote \(\vlambda =\left [\mC _{\vlambda }, \vm _{\vlambda }\right ]\) and \(\vmu = \left [\mC _{\vmu }, \vm _{\vmu }\right ]\). Then, \begin {alignat}{2} t\left (\vu , \alpha \,\vlambda + \beta \,\vmu \right ) &= \left (\alpha \,\mC _{\vlambda } + \beta \,\mC _{\vmu }\right )\,\vu + \left (\alpha \,\vm _{\vlambda } + \beta \,\vm _{\vmu }\right ) \nonumber \\ &= \alpha \,\left (\mC _{\vlambda }\vu + \vm _{\vlambda }\right ) + \beta \,\left (\mC _{\vmu }\,\vu + \vm _{\vmu }\right ) \nonumber \\ &= \alpha \,t\left (\vu , \vlambda \right ) + \beta \,t\left (\vu , \vmu \right ). \nonumber \end {alignat}\end{proof}
\prAtEndRestateiv*
\label{proofsection:prAtEndiv}\begin{proof}[Proof of \autoref{thm:prAtEndiv}]\phantomsection\label{proof:prAtEndiv}A distribution \(q\left (\cdot \right ) \in \mathcal {Q}\) in a location-scale family \(\mathcal {Q}\) is defined as \begin {align*} \rvvz \sim q\left (\cdot \right ) \iff \rvvz = t\left (\rvvu , \vlambda \right ),\; \rvvu \sim \phi \left (\cdot \right ). \end {align*} The reparameterization function \(t\) is defined as an affine transformation \begin {align*} t\left (\vu , \vlambda \right ) = \mC \,\vu + \vm \end {align*} for the location \(\vm \) and scale \(\mC \) parameters and their concatenation \(\vlambda = \left [\mC , \vm \right ]\). \par Furthermore, the base density \(\phi \left (\vz \right )\) of any location-scale log-concave family is log-concave. Therefore, it follows that \begin {alignat}{2} &\log \phi \left (t\left (\vu , \alpha \vlambda + (1 - \alpha )\,\vmu \right )\right ) \nonumber \\ &\quad = \log \phi \left ( \alpha \,t\left (\vu , \vlambda \right ) + (1 - \alpha )\,t\left (\vu , \vmu \right )\right ) &&\quad \text {\textit {\cref {thm:additive}}} \nonumber \\ &\quad = \alpha \,\log \phi \left (t\left (\vu , \vlambda \right )\right ) + (1 - \alpha )\,\log \phi \left (t\left (\vu , \vmu \right )\right ) &&\quad \text {\textit {Log-concavity of \(\phi \)}}. \nonumber \end {alignat}\end{proof}
\begin{restatable}[]{lemma}{prAtEndRestatev}\label{thm:prAtEndv}\label {thm:mixing_time} Assuming the kernel \(P_{\vlambda }\left (\veta , \cdot \right )\) satisfies \cref {thm:ergodicity}, the Hellinger mixing time \(\tau _{\text {Hel.}}\) is bounded as \begin {align*} \tau _{\text {Hel.}}\left (K_{\vlambda }, \epsilon \right ) \leq \frac {2}{\log \rho ^{-1}} \log \frac {1}{\epsilon } \end {align*}\end{restatable}
\label{proofsection:prAtEndv}\begin{proof}[Proof of \autoref{thm:prAtEndv}]\phantomsection\label{proof:prAtEndv}The following two inequalities are equivalent. \begin {align*} d_{\text {Hel.}}\left (\, P^t_{\vlambda }\left (\veta , \cdot \right ), \Pi \,\right ) &\leq \sqrt {\DTV { P^t_{\vlambda }\left (\veta , \cdot \right )}{\Pi }} \leq \rho ^{t / 2} \\ \log d_{\text {Hel.}}\left (\, P^t_{\vlambda }\left (\veta , \cdot \right ), \Pi \,\right ) &\leq \frac {t}{2} \log \rho \end {align*} \par The Hellinger mixing time \(\tau _{\text {Hel.}}\left (K_{\vlambda }, \epsilon \right )\) is the smallest \(t\) that statisfies the inequality \begin {align*} d_{\text {Hel.}}\left (\, P^t_{\vlambda }\left (\veta , \cdot \right ), \Pi \,\right ) &\leq \epsilon . \end {align*} Instead, we can find the \(t\prime > t\) that satisfies \begin {align*} \log d_{\text {Hel.}}\left (\, P^t_{\vlambda }\left (\veta , \cdot \right ), \Pi \,\right ) \leq \frac {t\prime }{2} \log \rho \leq \log \epsilon \end {align*} by solving the inequalities \begin {alignat*}{2} \frac {t\prime }{2} \log \rho &\leq \log \epsilon \\ t\prime &\geq \frac {2}{\log \rho } \log \epsilon &&\quad \text {\textit {Inequality flipped since \(\log \rho \leq 1\)}} \\ t\prime &\geq \frac {2}{\log \rho ^{-1}} \log \frac {1}{\epsilon } \end {alignat*}\end{proof}
\prAtEndRestatevi*
\label{proofsection:prAtEndvi}\begin{proof}[Proof of \autoref{thm:prAtEndvi}]\phantomsection\label{proof:prAtEndvi}\citet [Corollary 3.5]{duchi_ergodic_2012} provide a non-asymptotic convergence rate for the \textit {ergodic mirror descent} algorithm which computes the parameter update as \begin {align} \vlambda _{t+1} &= \argmin _{\vlambda \in \Lambda } \left \{\, \iprod {\,\vg \left (\vlambda , \veta _t\right )}{\vlambda \,} + \frac {1}{\alpha _t} D_{\psi }\left (\vlambda , \vlambda _{t}\right ) \,\right \}\label {eq:ergodic_mirror_descent} \\ \rvveta _{t+1} &\sim P_{\vlambda _{t}}\left (\veta _t, \cdot \right ) \nonumber \end {align} where \(D_{\psi }\) is the Bregman divergence defined as \begin {align*} D_{\psi }\left (\vlambda , \vlambda \prime \right ) \triangleq \psi \left (\vlambda \right ) - \psi \left (\vlambda \prime \right ) - \iprod { \nabla \psi \left (\vlambda \prime \right )}{\vlambda - \vlambda \prime } \end {align*} for some convex function \(\psi \). Our result is based on the fact that MCGD is a special case of the ergodic mirror descent algorithm. Specifically, by choosing \(\psi \left (\vlambda \right ) = \frac {1}{2} \norm {\vlambda }^2_2 \), we obtain \begin {alignat}{2} D_{\psi }\left (\vlambda , \vlambda \prime \right ) = \frac {1}{2} \norm {\vlambda - \vlambda \prime }_2^2 \leq \frac {1}{2} \, R^2.\label {eq:bregman} &&\quad \text {\textit {\cref {thm:compact}}} \end {alignat} This reduces the update in \cref {eq:ergodic_mirror_descent} into projected gradient descent which is the form used for Markov chain score climbing. \par Under our assumptions, \citet [Corollary 3.5]{duchi_ergodic_2012} show that, by assuming that the Hellinger mixing time is bounded as \begin {align} \tau _{\text {Hel.}}\left (K_{\vlambda }, \epsilon \right ) \leq \kappa _1 \log \left ( \kappa _2 /\epsilon \right ) \label {eq:hellinger_mixing} \end {align} for any \(\epsilon > 0\), and setting a decreasing stepsize \(\alpha _t = \alpha / \sqrt {t}\), it follows that \begin {align} &\E { \DKL {\pi }{q\,(\cdot ; {\overline {\vlambda }_{T}})} - \DKL {\pi }{q\left (\cdot ; {\vlambda ^*}_{T}\right )}} \nonumber \\ &\quad \leq \frac {R^2}{2 \, \alpha \, \sqrt {T}} + \frac {2 \, \alpha \, G^2}{\sqrt {T}}\left ( \kappa _1 \, \log \frac {\kappa _2}{\epsilon } \right ) + 3 \, \epsilon \, G \, R + \frac {R \, G \, \kappa _1 \, \log \frac {\kappa _2}{\epsilon }}{T}.\label {eq:original_bound} \end {align} \par From this, by setting the initial stepsize as \(\alpha = R / \left (G \sqrt {\kappa _1 \log \left (\kappa _2 \, T\right ) }\right )\) and \(\epsilon = 1/ \sqrt {T}\), \begin {alignat*}{2} &\E { \DKL {q\,(\cdot ; {\overline {\vlambda }_{T}})}{\pi } - \DKL {q\left (\cdot ; {\vlambda ^*}_{T}\right )}{\pi }} \\ &\leq \frac {R}{2 \, \alpha \, \sqrt {T}} + \frac {2 \, \alpha \, G^2}{\sqrt {T}}\left ( \kappa _1 \, \log \frac {\kappa _2}{\epsilon } \right ) + 3 \, \epsilon \, G \, R + \frac {R \, G \, \kappa _1 \, \log \frac {\kappa _2}{\epsilon }}{T}. &&\quad \text {\textit {\cref {eq:original_bound}}} \\ &= \frac {R \, G \, \sqrt {\kappa _1 \, \log \left (\kappa _2 \, T\right ) } }{2 \, \sqrt {T}} + \frac {2 \, R \, G}{\sqrt {T}} \frac { \kappa _1 \, \log \kappa _2 \, \sqrt {T} }{ \sqrt {\kappa _1 \log \left (\kappa _2 \, T\right )}} + \frac {3 \, G \, R}{\sqrt {T}} + \frac {R \, G \, \kappa _1 \, \log \left (\kappa _2 \, \sqrt {T}\right )}{T} &&\quad \text {\textit {Plugged value of \(\epsilon \) and \(\alpha \)}} \\ &\leq \frac {R \, G \, \sqrt {\kappa _1 \, \log \left (\kappa _2 \, T\right ) } }{2 \, \sqrt {T}} + \frac {2 \, R \, G}{\sqrt {T}} \frac { \kappa _1 \, \log \kappa _2 \, T }{ \sqrt {\kappa _1 \log \left (\kappa _2 \, T\right )}} + \frac {3 \, G \, R}{\sqrt {T}} + \frac {R \, G \, \kappa _1 \, \log \left (\kappa _2 \, T\right )}{T} &&\quad \text {\textit {Applied \(\log \sqrt {T} < \log T\)}} \\ &= \frac {R \, G \, \sqrt {\kappa _1 \, \log \left (\kappa _2 \, T\right ) } }{2 \, \sqrt {T}} + \frac {2 \, R \, G}{\sqrt {T}} \sqrt {\kappa _1 \, \log \left ( \kappa _2 \, T\right ) } + \frac {3 \, G \, R}{\sqrt {T}} + \frac {R \, G \, \kappa _1 \, \log \left (\kappa _2 \, T\right )}{T} &&\quad \text {\textit {Solved fraction}} \\ &= \frac {5 \, R \, G \, \sqrt {\kappa _1 \, \log \left (\kappa _2 \, T\right ) } }{2 \, \sqrt {T}} + \frac {3 \, G \, R}{\sqrt {T}} + \frac {R \, G \, \kappa _1 \, \log \left (\kappa _2 \, T\right )}{T}. &&\quad \text {\textit {Combined fractions}} \end {alignat*} \par From \cref {thm:mixing_time}, we retrieve the constants of \cref {eq:hellinger_mixing} as \( \kappa _1=\frac {2}{\log \rho ^{-1} },\; \kappa _2 = 1 \), which follows our result \begin {alignat*}{2} &\frac { 5 \, R \, G \, \sqrt {\kappa _1 \, \log \left (\kappa _2 \, T\right ) } }{ 2 \, \sqrt {T} } + \frac {3 \, G \, R}{\sqrt {T}} + \frac {R \, G \, \kappa _1 \, \log \left (\kappa _2 \, T\right )}{T} \\ &\quad = \frac { 5 \, R \, G \, \sqrt { \frac {2}{\log \rho ^{-1}} \, \log T } }{ 2 \, \sqrt {T} } + \frac {3 \, G \, R}{\sqrt {T}} + \frac {R \, G \, \frac {2}{\log \rho ^{-1}} \, \log T}{T} &&\quad \text {\textit {Plugged values of \(\kappa _1\) and \(\kappa _2\)}} \\ &\quad = \frac { 5 \, \sqrt {2} \, R \, }{ 2 } \, \frac { G \, \sqrt {\log T} }{ \log \rho ^{-1} \, \sqrt {T} \, } + 3 \, R \, \frac {G \, R}{\sqrt {T}} + 2 \, R \, \frac {G \, \log T}{ \log \rho ^{-1} \, T} &&\quad \text {\textit {Pulled constants forward}} \end {alignat*}\end{proof}
\begin{restatable}[]{lemma}{prAtEndRestatevii}\label{thm:prAtEndvii}\label {thm:product_measure_bound} For the probability measures \(p_1, \ldots , p_N\) and \(q_1, \ldots , q_N\) defined on a measurable space \((\mathsf {X}, \mathcal {A})\) and an arbitrary set \(A \in \mathcal {A}\), \begin {align*} &\abs { \int _{A^N} p_1\left (dx_1\right ) p_2\left (dx_2\right ) \times \ldots \times p_N\left (dx_N\right ) - q_1\left (dx_1\right ) q_2\left (dx_2\right ) \times \ldots \times q_N\left (dx_N\right ) } \\ &\qquad \leq \sum _{n=1}^N \abs { \int _{A} p_n\left (dx_n\right ) - q_n\left (dx_n\right ) } \end {align*}\end{restatable}
\label{proofsection:prAtEndvii}\begin{proof}[Proof of \autoref{thm:prAtEndvii}]\phantomsection\label{proof:prAtEndvii}By using the following shorthand notations \begin {alignat*}{2} p_{(1:N)}\left (dx_{(1:N)}\right ) &= p_1\left (dx_1\right ) p_2\left (dx_2\right ) \times \ldots \times p_N\left (dx_N\right ) \\ q_{(1:N)}\left (dx_{(1:N)}\right ) &= q_1\left (dx_1\right ) q_2\left (dx_2\right ) \times \ldots \times q_N\left (dx_N\right ), \end {alignat*} the result follows from induction as \begin {alignat}{2} &\abs { \int _{A^N} p_{(1:N)}\left (dx_{(1:N)}\right ) - q_{(1:N)}\left (dx_{(1:N)}\right ) } \nonumber \\ &\quad = \Bigg |\; \left ( \int _{A} p_1\left (dx_1\right ) - q_1\left (dx_1\right ) \right ) \, \int _{A^{N-1}} p_{(2:N)}\left (dx_{(2:N)}\right ) \nonumber \\ &\qquad \quad + \int _{A} q_1\left (dx_1\right ) \, {\left ( \int _{A^{N-1}} p_{(2:N)}\left (dx_{(2:N)}\right ) - q_{(2:N)}\left (dx_{(2:N)}\right ) \right )} \;\Bigg | \nonumber \\ &\quad \leq \Bigg | \int _{A} p_1\left (dx_1\right ) - q_1\left (dx_1\right ) \Bigg |\; \int _{A^{N-1}} p_{(2:N)}\left (dx_{(2:N)}\right ) \nonumber \\ &\qquad \quad + \int _{A} q_1\left (dx_1\right ) \, { \Bigg |\; \int _{A^{N-1}} p_{(2:N)}\left (dx_{(2:N)}\right ) - q_{(2:N)}\left (dx_{(2:N)}\right ) } \;\Bigg | &&\quad \text {\textit {Triangle inequality}} \nonumber \\ &\quad \leq \Bigg | \int _{A} p_1\left (dx_1\right ) - q_1\left (dx_1\right ) \Bigg |\; \nonumber \\ &\qquad \quad + { \Bigg |\; \int _{A^{N-1}} p_{(2:N)}\left (dx_{(2:N)}\right ) - q_{(2:N)}\left (dx_{(2:N)}\right ) } \;\Bigg |. &&\quad \text {\textit {Applied \(p_n\left (A\right ), q_n\left (A\right ) \leq 1 \)}} \nonumber \end {alignat}\end{proof}
\prAtEndRestateviii*
\label{proofsection:prAtEndviii}\begin{proof}[Proof of \autoref{thm:prAtEndviii}]\phantomsection\label{proof:prAtEndviii}the ergodic convergence rate of the i-SIR kernel is given by \citet {andrieu_uniform_2018}. \begin {alignat*}{2} \DTV {P^{k}\left (\veta , \cdot \right )}{\Pi } = \DTV {K^{k}\left (\vz , \cdot \right )}{\pi } \leq {\left (1 - \frac {N - 1}{2 w^* + N - 2}\right )}^k \end {alignat*} \par \begin {alignat}{2} &\E { \norm { g\left (\cdot , \rvveta \right ) }^2_{*} \,\middle |\, \mathcal {F}_{t} } \nonumber \\ &\quad = \E { \norm { g\left (\cdot , \rvveta \right ) }^2 \,\middle |\, \vz _{t-1},\, \vlambda _{t-1} } \nonumber \\ &\quad = \Esub {\rvvz \sim K\left (\vz _{t-1}, \cdot \right )}{ \norm { s\left (\cdot ; \rvvz \right ) }^2_{*} \,\middle |\, \vz _{t-1},\, \vlambda _{t-1} } \nonumber \\ &\quad = \int \sum ^{N}_{n=1} \frac { w\left (\vz _n\right ) }{ \sum ^{N}_{m=1} w\left (\vz _m\right ) } \norm { s\left (\cdot ; \vz _n\right ) }^2_{*} \prod ^{N}_{n=2} q\left (d\vz _n; \vlambda _{t-1}\right ) \nonumber \\ &\quad = \int \sum ^{N}_{n=1} \overline {w}\left (\vz _n\right ) \norm { s\left (\cdot ; \vz _n\right ) }^2_{*} \prod ^{N}_{n=2} q\left (d\vz _n\right ) \nonumber &&\quad \text {\textit { Define {\small \( {\overline {w}}\left (\vz _n\right ) = \frac { w\left (\vz _n\right ) }{ \sum ^{N}_{m=1} w\left (\vz _m\right ) } \) }}} \\ &\quad = \int \left ( \vw ^{\top }\, \vf \, \right ) \prod ^{N}_{n=2} q\left (d\vz _n; \vlambda _{t-1}\right ) \nonumber &&\quad \text {\textit { Define vectors {\small \( {\left [\vw \right ]}_n = \overline {w}\left (\vz _n\right ) \) }and {\small \( {\left [\,\vf \,\right ]}_n = \norm { s\left (\cdot ; \vz _n\right ) }^2_{*} \) }}} \\ &\quad \leq \sqrt { \Esub { q\left (\cdot , \vlambda _{t-1}\right ) }{ \vw ^{\top } \vw } \Esub { q\left (\cdot , \vlambda _{t-1}\right ) }{ \,\vf ^{\top }\vf \, } } \nonumber &&\quad \text {\textit {Cauchy-Schwarz inequality}} \\ &\quad = \sqrt { \Esub { \rvvz _n \sim q\left (\cdot , \vlambda _{t-1}\right ) }{ \sum ^{N}_{n=1} {\left ( \overline {w}\left (\rvvz _n\right ) \right )}^2 } \Esub { \rvvz _n \sim q\left (\cdot , \vlambda _{t-1}\right ) }{ \norm { s\left (\cdot ; \vz _n\right ) }^4_{*} } } \nonumber \\ &\quad \leq \sqrt { \Esub { \rvvz _n \sim q\left (\cdot , \vlambda _{t-1}\right ) }{ \norm { s\left (\cdot ; \vz _n\right ) }^4_{*} } } \nonumber &&\quad \text {\textit {Applied \(\sum ^N_{n=1} {\left (\overline {w}\left (\vz _n\right )\right )}^2 \leq \sum ^N_{n=1} \overline {w}\left (\vz _n\right ) = 1\)}} \\ &\quad \leq \sqrt { \sigma ^4 } \nonumber \\ &\quad = \sigma ^2 \nonumber \end {alignat} \par \end{proof}
\begin{restatable}[]{lemma}{prAtEndRestateix}\label{thm:prAtEndix}\label {thm:lambda_bound} For \(w^* = \sup _{\vz } w\left (\vz \right ) \), \(\lambda \left (\cdot \right )\) in~\cref {eq:T_lambda} is bounded as \[ \max \left (1 - \frac {1}{w}, 0\right ) \leq \lambda \left (w\right ) \leq 1 - \frac {1}{w^*}. \]\end{restatable}
\label{proofsection:prAtEndix}\begin{proof}[Proof of \autoref{thm:prAtEndix}]\phantomsection\label{proof:prAtEndix}The proof can be found in the proof of Theorem 3 of \citet {Smith96exacttransition}.\end{proof}
\begin{restatable}[]{lemma}{prAtEndRestatex}\label{thm:prAtEndx}\label {thm:tn_bound} For \(w^* = \sup _{\vz } w\left (\vz \right ) \), \(T_t\left (\cdot \right )\) in~\cref {eq:T_lambda} is bounded as \[ T_n\left ( w \right ) \leq \frac {n}{w} \, {\left (1 - \frac {1}{w^*}\right )}^{n-1}. \]\end{restatable}
\label{proofsection:prAtEndx}\begin{proof}[Proof of \autoref{thm:prAtEndx}]\phantomsection\label{proof:prAtEndx}\begin {alignat*}{2} T_n\left (w\right ) &= \int _w^{\infty } \frac {n}{v^2} \, \lambda ^{n-1}\left (v\right )\,dv &&\quad \text {\textit {\cref {eq:T_lambda}}} \\ &\leq \int _w^{\infty } \frac {n}{v^2} \, {\left (1 - \frac {1}{w^*}\right )}^{n-1}\,dv &&\quad \text {\textit {\cref {thm:lambda_bound}}} \\ &= n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \int _w^{\infty } \frac {1}{v^2} \,dv &&\quad \text {\textit {Pulled out constant}} \\ &= n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \left ( {-\left .\frac {1}{v}\right \rvert ^{\infty }_{w}} \right ) &&\quad \text {\textit {Solved indefinite integral}} \\ &= \frac {n}{w} \, {\left (1 - \frac {1}{w^*}\right )}^{n-1}. \end {alignat*} This upper bound is in general difficult to improve unless we impose stronger assumptions on \(\pi \) and \(q\).\end{proof}
\begin{restatable}[]{lemma}{prAtEndRestatexi}\label{thm:prAtEndxi}\label {thm:imh_expecation} For a positive test function \(f : \mathcal {Z} \rightarrow \mathbb {R}^{+}\), the estimate of a \(\pi \)-invariant independent Metropolis-Hastings kernel with a proposal \(q\) is bounded as \begin {align*} \Esub {K^n\left (\vz , \cdot \right )}{ f \,\middle |\, \vz } \leq n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \Esub {q}{f} + {\left (1 - \frac {1}{w^*}\right )}^n \, f\left (\vz \right ) \end {align*} where \(w\left (\vz \right ) = \pi \left (\vz \right ) / q\left (\vz \right )\) and \(w^* = \sup _{\vz } w\left (\vz \right ) \).\end{restatable}
\label{proofsection:prAtEndxi}\begin{proof}[Proof of \autoref{thm:prAtEndxi}]\phantomsection\label{proof:prAtEndxi}\begin {alignat*}{2} &\Esub {K^n\left (\vz , \cdot \right )}{ f \,\middle |\, \vz } \\ &\quad = \int T_n\left (w\left (\vz \right ) \vee w\left (\vz \prime \right )\right ) \, f\left (\vz \prime \right ) \, \pi \left (\vz \prime \right ) d\vz \prime + \lambda ^{n}\left (w\left (\vz \right )\right ) \, f\left (\vz \right ) &&\quad {\text {\textit {\cref {eq:imh_exact_kernel}}}} \\ &\quad \leq \int \frac {n}{w\left (\vz \right ) \vee w\left (\vz \prime \right )} \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \, f\left (\vz \prime \right ) \, \pi \left (\vz \prime \right ) d\vz \prime + \lambda ^{n}\left (w\left (\vz \right )\right ) \, f\left (\vz \right ) &&\quad {\text {\textit {\cref {thm:tn_bound}}}} \\ &\quad \leq \int \frac {n}{w\left (\vz \prime \right )} \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \, f\left (\vz \prime \right ) \, \pi \left (\vz \prime \right ) d\vz \prime + \lambda ^{n}\left (w\left (\vz \right )\right ) \, f\left (\vz \right ) &&\quad {\frac {1}{w\left (\vz \right ) \vee w\left (\vz \prime \right )} \leq \frac {1}{w\left (\vz \prime \right )}} \\ &\quad = n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \, \int \frac {1}{w\left (\vz \prime \right )} \, f\left (\vz \prime \right ) \, \pi \left (\vz \prime \right ) d\vz \prime + \lambda ^{n}\left (w\left (\vz \right )\right ) \, f\left (\vz \right ) &&\quad {\text {\textit {Pulled out constant}}} \\ &\quad = n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \, \int f\left (\vz \prime \right ) \, q\left (\vz \prime \right ) d\vz \prime + \lambda ^{n}\left (w\left (\vz \right )\right ) \, f\left (\vz \right ) &&\quad {\text {\textit {Definition of \(w\left (\vz \right )\)}}} \\ &\quad \leq n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \, \int f\left (\vz \prime \right ) \, q\left (\vz \prime \right ) d\vz \prime + {\left (1 - \frac {1}{w^*}\right )}^{n} \, f\left (\vz \right ) &&\quad {\text {\textit {\cref {thm:lambda_bound}}}} \\ &\quad = n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \Esub {q}{f} + {\left (1 - \frac {1}{w^*}\right )}^n \, f\left (\vz \right ). \end {alignat*}\end{proof}
\prAtEndRestatexii*
\label{proofsection:prAtEndxii}\begin{proof}[Proof of \autoref{thm:prAtEndxii}]\phantomsection\label{proof:prAtEndxii}\begin {alignat}{2} &\DTV {K^{k}\left (\veta , \cdot \right )}{\Pi } \nonumber \\ &\quad = \sup _{A} \abs { \Pi \left (A\right ) - P^{k}\left (\veta , A\right ) } &&\quad \text {\textit {Definition of \(d_{\text {TV}}\)}} \nonumber \\ &\quad \leq \sup _{A} \Bigg | \int _{A} \pi \left (d\vz \prime _1\right ) \times \ldots \times \pi \left (d\vz \prime _N\right ) \nonumber \\ &\qquad \qquad \qquad - K^{(k-1)\,N\,+1}\left (\vz _1, d\vz \prime _1\right ) \times \ldots \times K^{k\,N}\left (\vz _N, d\vz \prime _N\right ) \,\Bigg | \nonumber \\ &\quad \leq \sup _{A} \sum _{n=1}^N \abs { \int _{A} \pi \left (d\vz \prime _k\right ) - K^{(k-1)\,N + n}\left (\vz _n, d\vz \prime _n\right ) } &&\quad \text {\textit {\cref {thm:product_measure_bound}}} \nonumber \\ &\quad = \sum _{n=1}^N \DTV {K^{(k-1)\,N + n}\left (\vz _n, \cdot \right )}{\pi } &&\quad \text {\textit {Definition of \(d_{\text {TV}}\)}} \nonumber \\ &\quad \leq \sum _{n=1}^N \rho ^{(k-1)\,N + n} &&\quad \text {\textit {Geometric ergodicity}} \nonumber \\ &\quad = \rho ^{k\,N} \, \rho ^{-N} \, \frac {\rho - \rho ^{N+1}}{1 - \rho } &&\quad \text {\textit {Solved sum}} \nonumber \\ &\quad = \frac {\rho \, \left (1 - \rho ^N\right )}{\rho ^N \left (1 - \rho \right )} \, {\left ( \rho ^{N} \right )}^k \nonumber \end {alignat} \par \begin {alignat}{2} &\E { \norm { g\left (\cdot , \rvveta \right ) }^2_{*} \,\middle |\, \mathcal {F}_{t} } \nonumber \\ &\quad = \E { \norm { g\left (\cdot , \rvveta \right ) }^2 \,\middle |\, \vz _{t-1},\, \vlambda _{t-1} } \nonumber \\ &\quad = \E { \norm { \frac {1}{N}\sum ^{N}_{n=1} s\left (\cdot ; \rvvz _{n}\right ) }^2_{*} \,\middle |\, \vz _{t-1},\, \vlambda _{t-1} } \nonumber \\ &\quad \leq \E { \frac {1}{N^2} \sum ^{N}_{n=1} \norm {s\left (\cdot ; \rvvz _{n}\right ) }^2_{*} \,\middle |\, \vz _{t-1},\, \vlambda _{t-1} } &&\quad \text {\textit {Triangle inequality}} \nonumber \\ &\quad = \frac {1}{N^2}\sum ^{N}_{n=1} \Esub {\rvvz _{n} \sim K^n\left (\vz _{t-1}, \cdot \right )}{ \norm {s\left (\cdot ; \rvvz _{n}\right ) }^2_{*} \,\middle |\, \vz _{t-1},\, \vlambda _{t-1} } &&\quad \text {\textit {Linearity of expectation}} \nonumber \\ &\quad \leq \frac {1}{N^2}\sum ^{N}_{n=1} n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \Esub {\rvvz _n \sim q_{\text {def.}}\left (\cdot ; \vlambda \right )}{ \norm {s\left (\cdot ; \rvvz _n \right )}_{*}^2 } \nonumber \\ &\qquad + {\left (1 - \frac {1}{w^*}\right )}^{n} \, \norm {s\left (\cdot ; \vz _{t-1} \right )}_{*}^2 &&\quad \text {\textit {\cref {thm:imh_expecation}}} \nonumber \\ &\quad \leq \frac {1}{N^2}\sum ^{N}_{n=1} n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} \, L^2 + {\left (1 - \frac {1}{w^*}\right )}^{n} \, L^2 \nonumber \\ &\quad = \frac {L^2}{N^2}\sum ^{N}_{n=1} n \, {\left (1 - \frac {1}{w^*}\right )}^{n-1} + {\left (1 - \frac {1}{w^*}\right )}^{n} \nonumber &&\quad \text {\textit {Moved constant forward}} \\ &\quad = \frac {L^2}{N^2} \, \left [\, {\left (w^*\right )}^2 + w^* - {\left (1 - \frac {1}{w^*}\right )}^N \left ( {\left (w^*\right )}^2 + w^* + N\,w^* \right ) \,\right ] \nonumber &&\quad \text {\textit {Solved sum}} \\ &\quad = \frac {L^2}{N^2} \, \left [\, \frac {1}{2} N^2 + \frac {3}{2}\,N + \mathcal {O}\left (1/w^*\right ) \,\right ] \nonumber &&\quad \text {\textit {Laurent series expansion at \(w \rightarrow \infty \)}} \\ &\quad = L^2 \, \left [\, \frac {1}{2} + \frac {3}{2}\,\frac {1}{N} + \mathcal {O}\left (1/w^*\right ) \,\right ] \nonumber \end {alignat} The laurent approximation is useful for realistic values of \(w^*\) since it is bounded below exponentially by the KL divergence.\end{proof}
\prAtEndRestatexiii*
\label{proofsection:prAtEndxiii}\begin{proof}[Proof of \autoref{thm:prAtEndxiii}]\phantomsection\label{proof:prAtEndxiii}For our new scheme, \begin {alignat}{2} &\DTV {K^{k}\left (\veta , \cdot \right )}{\Pi } \nonumber \\ &\quad = \sup _{A} \abs { \Pi \left (A\right ) - P^{k}\left (\veta , A\right ) } &&\quad \text {\textit {Definition of \(d_{\text {TV}}\)}} \nonumber \\ &\quad \leq \sup _{A} \big |\; \int _{A} \pi \left (d\vz \prime _1\right ) \cdot \ldots \cdot \pi \left (d\vz \prime _N\right ) \nonumber \\ &\qquad \qquad \qquad - K^k\left (\vz _1, d\vz \prime _1\right ) \cdot \ldots \cdot K^k\left (\vz _N, d\vz \prime _N\right ) \;\big | \nonumber \\ &\quad \leq \sup _{A} \sum _{n=1}^N \abs { \int _{A} \pi \left (d\vz \prime _k\right ) - K^{k}\left (\vz _n, d\vz \prime _n\right ) } &&\quad \text {\textit {\cref {thm:product_measure_bound}}} \nonumber \\ &\quad = \sum _{n=1}^N \DTV {K^k\left (\vz _n, \cdot \right )}{\pi } &&\quad \text {\textit {Definition of TV distance}} \nonumber \\ &\quad \leq \sum _{n=1}^N \rho ^{k} &&\quad \text {\textit {Geometric ergodicity}} \nonumber \\ &\quad = N\,\rho ^{k} &&\quad \text {\textit {Solved sum}} \nonumber \end {alignat} \par \begin {alignat}{2} &\E { \norm { g\left (\cdot , \rvveta \right ) }^2_{*} \,\middle |\, \mathcal {F}_{t} } \nonumber \\ &\quad = \E { \norm { g\left (\cdot , \rvveta \right ) }^2 \,\middle |\, \vz _{t-1}^{(1:N)},\, \vlambda _{t-1} } \nonumber \\ &\quad = \E { \norm { \frac {1}{N}\sum ^{N}_{n=1} s\left (\cdot ; \rvvz _{n}\right ) }^2_{*} \,\middle |\, \vz _{t-1}^{(1:N)},\, \vlambda _{t-1} } \nonumber \\ &\quad \leq \E { \frac {1}{N^2} \sum ^{N}_{n=1} \norm {s\left (\cdot ; \rvvz _{n}\right ) }^2_{*} \,\middle |\, \vz _{t-1}^{(1:N)},\, \vlambda _{t-1} } &&\quad \text {\textit {Triangle inequality}} \nonumber \\ &\quad = \frac {1}{N^2}\sum ^{N}_{n=1} \Esub {\rvvz _{n} \sim K\left (\vz _{t-1}^{(n)}, \cdot \right )}{ \norm {s\left (\cdot ; \rvvz _{n}\right ) }^2_{*} \,\middle |\, \vz _{t-1}^{(1:N)},\, \vlambda _{t-1} } &&\quad \text {\textit {Linearity of expectation}} \nonumber \\ &\quad \leq \frac {1}{N^2}\sum ^{N}_{n=1} \Esub {\rvvz _n \sim q_{\text {def.}}\left (\cdot ;\vlambda \right )}{ \norm {s\left (\cdot ; \rvvz _n \right )}_{*}^2 } + {\left (1 - \frac {1}{w^*}\right )} \, \norm {s\left (\cdot ; \vz _{t-1}^{(n)} \right )}_{*}^2 &&\quad \text {\textit {\cref {thm:imh_expecation}}} \nonumber \\ &\quad \leq \frac {1}{N^2}\sum ^{N}_{n=1} L^2 + {\left (1 - \frac {1}{w^*}\right )} \, L^2 \nonumber \\ &\quad = \frac {L^2}{N^2} \sum ^{N}_{n=1} 1 + {\left (1 - \frac {1}{w^*}\right )} \nonumber &&\quad \text {\textit {Moved constant forward}} \\ &\quad = L^2 \left [ \frac {1}{N} + \frac {1}{N}\,{\left (1 - \frac {1}{w^*}\right )} \right ]. \nonumber &&\quad \text {\textit {Solved sum}} \end {alignat}\end{proof}
