
\begin{theoremEnd}{theorem}\label{thm:msc}
  MSC~\citep{NEURIPS2020_b2070693} is obtained by defining 
  {%\small
  \begin{align*}
  P_{\lambda}^n\left(\veta, d\veta\prime\right)
  = 
  K_{\lambda}^n\left(\vz, d\vz\prime\right)
  \end{align*}
  }
  with  \(\veta_t = \vz_t\) where \(K_{\vlambda}\left(\vz, \cdot\right)\) is the conditional importance sampling (CIS) kernel~\citep{NEURIPS2020_b2070693} with \(q_{def.}\left(\cdot; \vlambda\right)\) as its proposal distribution.
  Then, given~\cref{thm:bounded_weight,thm:bounded_score}, the mixing rate and the gradient bounds are given as
  {\small
  \begin{align*}
  \DTV{P_{\vlambda}^n\left(\veta, \cdot\right)}{\Pi} \leq  {\left(1 - \frac{N - 1}{2 w^* + N - 2}\right)}^n\quad \text{and}\quad
  {\small
  \E{ \norm{ \vg\left(\vlambda, \rvveta\right) }_{*}^2 \,\middle|\, \mathcal{F}_{t} } \leq  L^2,
  }
  \end{align*}
  }
  where \(w^* = \sup_{\vz} \pi\left(\vz\right) / q_{\text{def.}}\left(\vz\right)\).
\end{theoremEnd}
\begin{proofEnd}
  MSC is described in~\cref{alg:msc}. 
  At each iteration, it performs a single MCMC transition with the CIS kernel where it internally uses \(N\) proposals.

  \paragraph{Ergodicity of the Markov Chain}
  The ergodic convergence rate \(P_{\vlambda}\) is equal to that of the i-SIR kernel, whhich has been given by \citet{andrieu_uniform_2018} as
  \begin{alignat*}{2}
    \DTV{P^{n}\left(\veta, \cdot\right)}{\Pi}
    =
    \DTV{K^{n}\left(\vz, \cdot\right)}{\pi}
    \leq
    {\left(1 - \frac{N - 1}{2 w^* + N - 2}\right)}^n.
  \end{alignat*}

  \paragraph{\textbf{Bound on the Gradient Variance}}
  The bound on the gradient variance is straightforward given \cref{thm:bounded_score}.
  For simplicity, we denote the rejection state as \(\vz^{(1)} = \vz_{t-1} \).
  Then,
  \begin{alignat}{2}
    &\E{ \norm{ \vg\left(\vlambda, \rvveta\right) }_{2} \,\middle|\, \mathcal{F}_{t} }
    \nonumber
    \\
    &\;=
    \E{ \norm{ \vg\left(\vlambda, \rvveta\right) }_2 \,\middle|\, \mathcal{F}_{t}}
    \nonumber
    \\
    &\;=
    \Esub{\rvvz \sim K\left(\vz_{t-1}, \cdot\right)}{
      \norm{ \vs\left(\vlambda; \rvvz\right) }_{*} \,\middle|\,
      \vlambda_{t-1}, \vz_{t-1}
    }
    \nonumber
    \\
    &\;=
    \int
    \sum^{N}_{n=1}
    \frac{
      w\left(\vz^{(n)}\right)
    }{
      \sum^{N}_{m=1} w\left(\vz^{(n)}\right)
    }
    \norm{ \vs\left(\cdot; \vz^{(n)}\right) }^2_{*}
    \prod^{N}_{n=2}
    q\left(d\vz^{(n)}; \vlambda_{t-1}\right)
    \nonumber
    &&\quad\text{\textit{\citep{andrieu_uniform_2018}}}
    \\
    &\;\leq
    L^2 \,
    \int
    \sum^{N}_{n=1}
    \frac{
      w\left(\vz^{(n)}\right)
    }{
      \sum^{N}_{m=1} w\left(\vz^{(n)}\right)
    }
    \prod^{N}_{n=2}
    q\left(d\vz^{(n)}; \vlambda_{t-1}\right)
    \nonumber
    &&\quad\text{\textit{\cref{thm:bounded_score}}}
    \\
    &\;=
    L^2 \,
    \int
    \prod^{N}_{n=2}
    q\left(d\vz^{(n)}; \vlambda_{t-1}\right)
    \nonumber
   &&\quad\text{\textit{The sum of weights is 1}}
    \\
    &\;=
    L^2.
    \nonumber
  \end{alignat}

  %% This form coincides with solving the expectation of the self-normalized importance sampling estimator, which is well known to be challenging~\citep{robert_monte_2004}.
  %% We instead approximate the expectation by defining the random variables
  %% \(
  %% X = \sum^{N}_{n=1} w\left(\vz_n\right) \norm{ s\left(\cdot; \vz_n\right) }^2_{*}
  %% \)
  %% and
  %% \(
  %% Y = \sum^{N}_{m=1} w\left(\vz_m\right)
  %% \),
  %% use the delta method as
  %% \begin{alignat*}{2}
  %%   \E{\frac{\rvX}{\rvY} \;\middle|\; Z} &\approx \frac{\E{\rvX \mid Z }}{\E{\rvY \mid Z}} + \mathcal{O}\left(\frac{1}{{\E{\rvX \mid Z}}^2}\right).
  %% \end{alignat*}
  %% The required expectations are obtained as
  %% \begin{alignat}{2}
  %%   &\E{\rvX \mid \lambda_{t-1}, \vz_{t-1}}
  %%   \\
  %%   &\;=
  %%   \int \sum^{N}_{n=1} w\left(\vz_n\right) \norm{ s\left(\cdot; \vz_n\right) }^2_{*}
  %%   \prod^{N}_{n=2}
  %%   q\left(d\rvvz_n\right)
  %%   \nonumber
  %%   \\
  %%   &\quad=
  %%   \sum^{N}_{n=1} \int w\left(\vz_n\right) \norm{ s\left(\cdot; \vz_n\right) }^2_{*}
  %%   \prod^{N}_{n=2}
  %%   q\left(d\rvvz_n\right)
  %%   &&\quad\text{\textit{Swapped integral and sum}}
  %%   \nonumber
  %%   \\
  %%   &\quad=
  %%   \left\{\;
  %%   \sum^{N}_{n=2} \int w\left(\vz_n\right) \norm{ s\left(\cdot; \vz_n\right) }^2_{*}
  %%   \prod^{N}_{n=2} q\left(d\rvvz_n\right)
  %%   \right\}
  %%   +
  %%   w\left(\vz_1\right) \norm{ s\left(\cdot; \vz_1\right) }^2_{*}
  %%   &&\quad\text{\textit{Pulled out rejection state}}
  %%   \nonumber
  %%   \\
  %%   &\quad=
  %%   \left\{\;
  %%   \sum^{N}_{n=2} \int \frac{\pi\left(\vz_n\right)}{q\left(\vz_n\right)} \norm{ s\left(\cdot; \vz_n\right) }^2_{*}
  %%   \prod^{N}_{n=2}
  %%   q\left(d\rvvz_n\right)
  %%   \right\}
  %%   +
  %%   w\left(\vz_1\right) \norm{ s\left(\cdot; \vz_1\right) }^2_{*}
  %%   &&\quad\text{\textit{Definition of \(w\left(\vz\right)\)}}
  %%   \nonumber
  %%   \\
  %%   &\quad=
  %%   \sum^{N}_{n=2} \int \pi\left(d\vz_n\right) \norm{ s\left(\cdot; \vz_n\right) }^2_{*}
  %%   +
  %%   w\left(\vz_1\right) \norm{ s\left(\cdot; \vz_1\right) }^2_{*}
  %%   &&\quad\text{\textit{Cancelled out \(q\left(\cdot\right)\)}}
  %%   \nonumber
  %%   \\
  %%   &\quad=
  %%   \left(N-1\right) \, \Esub{\pi}{\norm{ s\left(\cdot; \rvvz\right) }^2_{*} }
  %%   +
  %%   w\left(\vz_1\right) \norm{ s\left(\cdot; \vz_1\right) }^2_{*}
  %%   \nonumber
  %%   \\
  %%   &\quad=
  %%   \left(N-1\right) \, \Esub{\pi}{\norm{ s\left(\cdot; \rvvz\right) }^2_{*} }
  %%   +
  %%   w\left(\vz_{t-1}\right) \norm{ s\left(\cdot; \vz_{t-1}\right) }^2_{*}
  %%   \nonumber
  %% \end{alignat}
  %% and similarly,
  %% \begin{alignat}{2}
  %%   \E{\rvY \mid \lambda_{t-1}, \vz_{t-1}}
  %%   &\quad= 
  %%   \int \sum^{N}_{n=1} w\left(\vz_n\right) \prod^{N}_{n=2} q\left(d\vz_n\right) 
  %%   \nonumber
  %%   \\
  %%   &\quad= 
  %%   \left\{\; \int \sum^{N}_{n=2} w\left(\vz_n\right) \prod^{N}_{n=2} q\left(d\vz_n\right) \;\right\} + w\left(\vz_1\right)
  %%   &&\quad\text{\textit{Pulled out rejection state}}
  %%   \nonumber
  %%   \\
  %%   &\quad= 
  %%   \left\{\; \sum^{N}_{n=2} \int w\left(\vz_n\right) \prod^{N}_{n=2} q\left(d\vz_n\right) \;\right\} + w\left(\vz_1\right)
  %%   &&\quad\text{\textit{Swapped integral and sum}}
  %%   \nonumber
  %%   \\
  %%   &\quad= 
  %%   \left\{\; \sum^{N}_{n=2} \int \frac{\pi\left(\vz_n\right)}{q\left(\vz_n\right)} \prod^{N}_{n=2} q\left(d\vz_n\right) \;\right\} + w\left(\vz_1\right)
  %%   &&\quad\text{\textit{Definition of \(w\left(\vz\right)\)}}
  %%   \nonumber
  %%   \\
  %%   &\quad= 
  %%   \left\{\; \sum^{N}_{n=2} \int \pi\left(d\vz_n\right) \;\right\} + w\left(\vz_1\right)
  %%   &&\quad\text{\textit{Cancelled out \(q\left(\cdot\right)\)}}
  %%   \nonumber
  %%   \\
  %%   &\quad= 
  %%   N - 1 + w\left(\vz_{t-1}\right)
  %%   \nonumber
  %% \end{alignat}
  %% Therefore, 
  %% \begin{alignat}{2}
  %%   \E{\frac{\rvX}{\rvY} \;\middle|\; Z}
  %%   &\approx
  %%   \frac{
  %%     \left(N-1\right) \, \Esub{\pi}{\norm{ s\left(\cdot; \rvvz\right) }^2_{*} }
  %%     +
  %%     w\left(\vz_1\right) \norm{ s\left(\cdot; \vz_1\right) }^2_{*}
  %%   }{
  %%     N-1 + w\left(\vz_1\right)
  %%   }
  %%   + \mathcal{O}\left(\frac{1}{{\left(N-1\right)}^2}\right)
  %%   \nonumber
  %%   \\
  %%   &\leq
  %%   \frac{
  %%     \left(N-1\right) \, \Esub{\pi}{\norm{ s\left(\cdot; \rvvz\right) }^2_{*} }
  %%     +
  %%     w^* \norm{ s\left(\cdot; \vz_1\right) }^2_{*}
  %%   }{
  %%     N-1
  %%   }
  %%   + \mathcal{O}\left(\frac{1}{{\left(N-1\right)}^2}\right)
  %%   &&\quad\text{\textit{\(w\left(\cdot\right) \leq w^*\)}}
  %%   \nonumber
  %%   \\
  %%   &\leq
  %%   \frac{
  %%     \left(N-1\right) \, L^2
  %%     +
  %%     w^* L^2
  %%   }{
  %%     N-1
  %%   }
  %%   + \mathcal{O}\left(\frac{1}{{\left(N-1\right)}^2}\right)
  %%   \nonumber
  %%   \\
  %%   &=
  %%   L^2
  %%   \left[
  %%   1
  %%   +
  %%   \frac{
  %%     w^*
  %%   }{
  %%     N-1
  %%   }
  %%   \right]
  %%   + \mathcal{O}\left(\frac{1}{{\left(N-1\right)}^2}\right)
  %%   \nonumber
  %% \end{alignat}
\end{proofEnd}

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
