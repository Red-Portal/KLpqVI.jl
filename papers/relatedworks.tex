
\section{Related Works}
\subsection{Connections in Variational Inference}
\paragraph{Inclusive VI}
\citet{DBLP:journals/corr/BornscheinB14} propose RWS which minimizes the inclusive KL divergence by occasinally utilizing independent samples from the target posterior.
\citep{kim2021adaptive} can be regarded as a blend of MSC and RWS, where an MCMC chain replaces the SNIS estimates the sleep phase updates.

\paragraph{MCMC in VI}
While VI has been regarded as a competitor to MCMC, many VI methods have attempted to make it part of their mechanism.
Some examples include~\citep{pmlr-v97-ruiz19a}.


\subsection{Connections with Adaptive Markov-Chain Monte Carlo}
The major technical difference between MSC and previous adaptive MCMC methods minimizing the inclusive KL is the use of stochastic gradients.

\citet{10.1007/s11222-008-9110-y, garthwaite_adaptive_2016} discuss the use of stochastic approximation in adaptive MCMC.
The containment condition is known to generally hold in practice~\citep{rosenthal_optimal_, bai_containment_2011}.
Consequently, recent works on adaptive MCMC have mainly focused on enforcing the diminishing adaptation condition~\citep{wang_adaptive_2013}.
In the context of MSC, the diminishing adaptation condition is statisfied by using a stepsize schedule such that \(\gamma_k \rightarrow 0\).
Thus, it should be possible to treat \(\vz^{(i)}_t\) as genuine samples from the posterior.


\paragraph{Adaptive IMH}
Adaptive MCMC methods based on independent proposals~\citep{andrieu_ergodicity_2006, keith_adaptive_2008, holden_adaptive_2009, giordani_adaptive_2010} are very similar with our work.
In fact,~\citet{keith_adaptive_2008} adapt the proposal distribution using the cross-entropy method, which is equivalent to inclusive variational inference, and .
Meanwhile,~\citet{giordani_adaptive_2010} use \(w\,q_0(\vz) + (1-w)\,q_{\vlambda}(\vz)\) for some \(0<w<1\) as the proposal distribution where \(q_0\) is a heavy tailed distribution in the spirit of defensive mixtures~\citep{hesterberg_weighted_1995}.
This is to ensure \(w(\vz) < \infty\), which is necessary for having geometric ergodicity~\citep{10.2307/2242610}.
With IMH proposals, this is actually quite restrictive and~\citet{10.1007/s11222-008-9110-y} provide a very simple example in which \(w(\vz)\) is not bounded.
However, this condition is equivalent to assuming that the inclusive KL is bounded with a constant \(\log M\) since
\begin{align}
  \DKL{p}{q_{\vlambda}} = \int p(\vz\mid\vx) \log w(\vz)\,d\vz \leq \int p(\vz\mid\vx) \log M \, d\vz = \log M.
\end{align}
Therefore, for problems where MSC is not geometricaly ergodic, inclusive VI would also fail to converge.
On the other hand, for problems where MSC converges without problem, defensive mixtures shouldn't be necessary.
for problems where \(w(\vz)\) is not bounded, virtually all inclusive VI methods, including SNIS and RWS, will fail to work, as their weights will have very high variance~\citep{mcbook}.

The boundedness of \(w(\vz)\) is more related to model specification and the selection of the variational family \(\mathcal{Q}\).
A research direction in the interest of both adaptive MCMC and inclusive VI would be to use a varitional family of heavier-tailed distributions such as elliptical distribtions~\citet{NEURIPS2018_25db67c5}.

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
