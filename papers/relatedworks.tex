
\section{Related Works}
\subsection{Connections in Variational Inference}
\paragraph{Inclusive VI}
\citet{DBLP:journals/corr/BornscheinB14} propose RWS which minimizes the inclusive KL divergence by occasinally utilizing independent samples from the target posterior.
\citep{kim2021adaptive} can be regarded as a blend of MSC and RWS, where an MCMC chain replaces the SNIS estimates the sleep phase updates.

\paragraph{MCMC in VI}
While VI has been regarded as a competitor to MCMC, many VI methods have attempted to make it part of their mechanism.
Some examples include~\citep{pmlr-v97-ruiz19a}.


\subsection{Connections with Adaptive Markov-Chain Monte Carlo}
The major technical difference between MSC and previous adaptive MCMC methods minimizing the inclusive KL is the use of stochastic gradients.

\citet{10.1007/s11222-008-9110-y, garthwaite_adaptive_2016} discuss the use of stochastic approximation in adaptive MCMC.
The containment condition is known to generally hold in practice~\citep{rosenthal_optimal_, bai_containment_2011}.
Consequently, recent works on adaptive MCMC have mainly focused on enforcing the diminishing adaptation condition~\citep{wang_adaptive_2013}.
In the context of MSC, the diminishing adaptation condition is statisfied by using a stepsize schedule such that \(\gamma_k \rightarrow 0\).
Thus, it should be possible to treat \(\vz^{(i)}_t\) as genuine samples from the posterior.


\paragraph{Adaptive IMH}
Adaptive MCMC methods based on independent proposals~\citep{keith_adaptive_2008, holden_adaptive_2009, giordani_adaptive_2010} are very similar with our work.
In fact,~\citet{keith_adaptive_2008} adapt the proposal distribution using the cross-entropy method, which is equivalent to inclusive variational inference.
Meanwhile,~\citet{giordani_adaptive_2010} use \(w\,q_o(\vz) + (1-w)\,q_{\vlambda}(\vz)\) as the proposal distribution where \(q_0\) is a heavy tailed distribution in the spirit of defensive mixtures~\citep{hesterberg_weighted_1995}.
This is to ensure \(w(\vz) < \infty\), which is necessary for having geometric ergodicity.
However, this condition is equivalent to assuming that the inclusive KL is bounded with a constant \(\log M\) since
\begin{align}
  \DKL{p}{q_{\vlambda}} = \int p(\vz\mid\vx) \log w(\vz)\,d\vz \leq \int p(\vz\mid\vx) \log M \, d\vz = \log M.
\end{align}
Thus, for problems which inclusive VI works, defensive mixtures shouldn't be necessary.

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
