
Recently, variational inference (VI) methods that minimize the inclusive Kullback-Leibler (KL) divergence by score climbing have been developed.
These methods perform stochastic gradient descent by obtaining noisy estimates of the score function using Markov-chain Monte Carlo (MCMC).
While multiple different ways to estimate the score with MCMC have been utilized, the design options have yet to be investigated.
This paper proposes the \textit{parallel state estimator}, a simple scheme that achieves lower variance than the previously utilized estimators.
Although our estimator uses multiple short Markov chains, we theoretically show that this does not necessarily result in higher bias.
We empirically verify our results on general Bayesian inference problems.

%Our experiments show that, when using our proposed scheme, inclusive KL divergence minimization is competitive against evidence lower bound minimization.
%Our results motivate the use of the inclusive KL divergence for VI.

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
