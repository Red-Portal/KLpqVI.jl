
\section{Introduction}
Given an observed data \(\vx\) and a latent variable \(\vz\), Bayesian inference aims to analyze \(p\,(\vz\,|\,\vx)\) given an unnormalized joint density \(p\,(\vz,\,\vx)\) where the relationship is given by Bayes' rule such that \(p\,(\vz\,|\,\vx) = {p\,(\vz,\,\vx)}/{p\,(\vx)} \propto p\,(\vz,\,\vx)\).
Instead of working directly with the target distribution \(p\,(\vz\,|\,\vx)\), variational inference (VI,~\citealt{jordan_introduction_1999, blei_variational_2017, zhang_advances_2019}) searches for a variational approximation \(q_{\lambda}(\vz)\) that is similar to \(p\,(\vz\,|\,\vx)\) according to a discrepancy measure \(D\,(p,\, q_{\vlambda})\).

Naturally, choosing a good discrepancy measure, or objective function, is a critical part of the problem.
This fact had lead to a quest for good divergence measures~\citep{NIPS2016_7750ca35, NIPS2017_35464c84, NEURIPS2018_1cd138d0, pmlr-v97-ruiz19a}.
So far, the exclusive KL divergence \(\DKL{q_{\lambda}}{p}\) (or reverse KL divergence) has been used ``exclusively'' among various discrepancy measures.
This is partly because the exclusive KL is defined as an average over \(q_{\lambda}(\vz)\), which can be estimated efficiently.
By contrast, the inclusive KL is defined as
%
%\vspace{-0.02in}
\begin{align}
  %% \DKL{p}{q_{\lambda}} = \int p\,(\vz\mid\vx) \log\big(\, p\,(\vz\mid\vx)/q_{\lambda}(\vz) \,\big)\,d\vz
  %% = \Esub{p(\vz\mid\vx)}{\log\big(\, p\,(\vz\mid\vx)/q_{\lambda}(\vz) \,\big) } \label{eq:klpq}
  \DKL{p}{q_{\lambda}} = \int p\,(\vz\mid\vx) \log \frac{p\,(\vz\mid\vx)\,}{\,q_{\lambda}(\vz)} \,d\vz
  = \Esub{p(\vz\mid\vx)}{\log \frac{p\,(\vz\mid\vx)\,}{\,q_{\lambda}(\vz)} } \label{eq:klpq}
\end{align}
%\vspace{-0.02in}
%
\noindent where the average is taken over \(p\,(\vz\,|\,\vx)\). 
Interestingly, this is a chicken-and-egg problem as our goal is to obtain \(p\,(\vz\,|\,\vx)\) in the first place.
Despite this challenge, minimizing~\eqref{eq:klpq} has drawn the attention of researchers because it can overcome some known limitations of the exclusive KL~\citep{minka2005divergence, mackay_local_2001}.

For performing inclusive VI,~\citet{NEURIPS2020_b2070693, pmlr-v124-ou20a} recently proposed \textit{Markovian score climbing} (MSC), which is a blend of Markov-chain Monte Carlo (MCMC) and variational inference.
In MSC, stochastic gradients of the inclusive KL are obtained by operating a Markov-chain in parallel with the VI optimizer.
In this paper, we find an interesting property of MSC when it is combined with specific types of MCMC kernels.
Specifically, we show that \textit{independent Metropolis-Hastings} (IMH,~\citealt{robert_monte_2004}) type kernels can automatically trade off bias and variance when used for MSC.
This family of kernels includes the \textit{condition importance sampling} (CIS,~\citealt{NEURIPS2020_b2070693}) kernel, which was originally proposed for MSC.
Surprisingly, this automatic tradeoff property is unique to IMH type kernels and does not occur in MCMC kernels with state-dependent proposals such as Hamiltonian Monte Carlo (HMC,~\citealt{duane_hybrid_1987, neal_mcmc_2011, betancourt_conceptual_2017}).

Following our analysis of the CIS kernel, we also show that its performance can degrade with the number of proposals (which is equivalent to the \textit{per-transition computational budget}) used in each Markov-chain transition.
As a simple solution to this, we propose to use parallel IMH (MSC-PIMH) chains, which reduce variance given the same amount of computation.
We evaluate the performance of MSC with PIMH against other inclusive VI~\citep{DBLP:journals/corr/BornscheinB14, NEURIPS2020_b2070693} and exclusive VI~\citep{pmlr-v33-ranganath14, JMLR:v18:16-107} methods.
%Finally, some interesting connections with adaptive MCMC methods~\citep{10.1007/s11222-008-9110-y} are discussed.

\vspace{-0.1in}
\paragraph{Contribution Summary}
\begin{enumerate*}[label=\textbf{(\roman*)}]
\item We propose the parallel state estimator for using MCMC to estimate the score function in inclusive VI (\textbf{\cref{section:overview}}).
\item We theoretically compare the bias and variance of the previously proposed MCMC estimation schemes against the parallel state estimator (\textbf{\cref{section:theory}}).
\item We experimentally compare the VI performance of the considered MCMC estimation schemes on general Bayesian inference benchmark problems (\textbf{\cref{section:eval}}).
%\item We discuss connections with adaptive IMH methods (\textbf{\cref{section:related}}).
\end{enumerate*}

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
