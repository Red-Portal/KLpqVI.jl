
%\vspace{-0.05in}
\section{Chain Wielding Strategies for Markov-chain Monte Carlo Estimators in Inclusive Variational Inference}
\vspace{-0.05in}
\subsection{Overview of Prevoius Estimation Strategies}\label{section:jsa_msc}
%
\vspace{-0.05in}

\paragraph{Overview}
Recently,~\citeauthor{NEURIPS2020_b2070693} and~\citeauthor{pmlr-v124-ou20a} proposed two similar but independent methods for performing inclusive variational inference.
Both methods estimate the score gradient by operating a Markov-chain in parallel with the VI optimization sequence.
Also, they both use MCMC kernels that can effectively used the variational approximation \(q_{\vlambda_t}(\vz)\).
Because of this, compared to previous VI approaches~\citep{pmlr-v97-ruiz19a, pmlr-v70-hoffman17a} that use expensive MCMC kernels such as Hamiltonian Monte Carlo, both methods are computationally efficient. 

\vspace{-0.05in}
\paragraph{Markovian Score Climbing and the Single State Estimator}
In Markovian score climbing (MSC), \citep{NEURIPS2020_b2070693} estimate the score gradient by performing an MCMC iteration and update the parameters such that
\vspace{-0.05in}
\begin{align}
  &\vz_t \sim K\left(\vz_{t-1}, \cdot \right) &g_{\text{single-CIS}}(\vlambda) = s\,(\vz_t; \vlambda)
\end{align}
where \(K\left(\vz_{t-1}, \cdot\right)\) is a MCMC kernel leaving \(p\,(\vz\mid\vx)\) invariant and \(g_{\text{single}}\left(\vlambda\right)\) denotes the score estimator.
For \(K\left(\vz_{t-1}, \cdot\right)\), they propose a new type of kernel inspired by particle MCMC~\cite{andrieu_particle_2010}, the conditional importance sampling (CIS) kernel.
Since the estimator uses \textit{a single state} created by the CIS kernel, we call it the single state estimator with the CIS kernel (single-CIS).
The CIS kernel internally uses \(N\) samples from the \(q_{\vlambda}(\vz)\).
Thus, when compared to MCMC kernels that only use a single sample from \(q_{\vlambda}(\vz)\), it is \(N\) times more expensive, but hopefully, statistically superior.
Unfortunately, we will show that this is not the case.

\vspace{-0.05in}
\paragraph{Joint Stochastic Approximation and the Sequential State Estimator}
On the other hand, at each SGD iteration \(t\),~\citep{pmlr-v124-ou20a} perform \(N\) sequential Markov-chain transitions and use the average of the intermediate states for estimation.
That is, for the index \(i \in \{1, \ldots, N\}\),
\vspace{-0.05in}
\begin{align}
  &\vz_{T+i} \sim K^i\left(\vz_{T}, \cdot \right) &g_{\text{seq.-IMH}}(\vlambda) = \frac{1}{N} \sum_{i=1}^N s\,(\vz_{T+i}; \vlambda)
\end{align}
where \(\vz_T\) is the last Markov-chain state of the previous SGD iteration.
For the MCMC kernel, they use the classic independent Metropolis-Hastings (IMH,~\citealt[Algorithm 25]{robert_monte_2004}~\citealt{hastings_monte_1970}) algorithm, which uses only a single sample from \(q_{\vlambda}(\vz)\).
Therefore, the cost of \(N\) state transitions with IMH is similar to the cost of a single transition with CIS.
Since the estimator uses sequential states, we call it the sequential state esimator with the IMH kernel (seq.-IMH)

\vspace{-0.05in}
\paragraph{Additional  Notes on JSA}
Before preoceeding, we acknowledge that the setup of~\citet{pmlr-v124-ou20a} is slightly different than what we described.
Their MCMC kernel leave \(p\left(\vz_j\mid\vx_j \right)\) invariant for a single datapoint \(\vx_j\), which is only possible when the datapoints are independently, identically distributed (\textit{iid}) under the probabilistic model.
We interpret their method more generally and assume that we only have a kernel that can leave \(p\left(\vz\mid\vx \right)\) invariant.

\subsection{Overview of Markov-Chain Monte Carlo Score Estimation Strategies}\label{section:overview}

\begin{figure*}
  \vspace{-0.4in}
    \centering
    \begin{subfigure}[b]{0.25\textwidth}
        \centering
        \includegraphics[scale=0.25]{figures/diagram_1.png}
        \caption{Single state estimator}\label{fig:single}
    \end{subfigure}
    \begin{subfigure}[b]{0.35\textwidth}
        \centering
        \includegraphics[scale=0.25]{figures/diagram_2.png}
        \caption{Sequential state estimator}\label{fig:seq}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[scale=0.25]{figures/diagram_3.png}
        \caption{Parallel state estimator}\label{fig:par}
    \end{subfigure}
    \caption{Visualization of different ways of combining MCMC with stochastic approximation variational inference.
    The index \(t\) denotes the stochastic approximation iteration.
    The dark circles denote the MCMC samples used for estimating the score gradient at \(t=2\).
    }\label{fig:overview}
\end{figure*}

\vspace{-0.05in}
\paragraph{Single State and Sequential State Estimators}
The two different MCMC estimators used in MSC and JSA represent two different ways of using a fixed computational budget.
The former uses a computationally expensive, but hopefully statistically superior, MCMC kernel with less samples, while the latter uses a cheaper MCMC kernel with more samples.
Illustrations of the two schemes are shown in~\cref{fig:single,fig:seq}.
Detailed pseudocodes of the considered schemes are provided in the \textit{supplementary material}.

\vspace{-0.05in}
\paragraph{Parallel State Estimator}
In this work, we will add a new scheme into the mix: the parallel state estimator.
Similarly with the sequential state estimator, we use the cheaper IMH kernel, but instead of applying the MCMC kernel \(N\) times to a single chain, we apply the MCMC kernel a single time to \(N\) \textit{parallel Markov-chains}.
That is, for each Markov-chain \(i \in \{1, \ldots, N\}\),
%
\vspace{-0.05in}
\begin{align}
  &\vz_{t}^{(i)} \sim K\big(\vz_{t-1}^{(i)}, \cdot \big) &g_{\text{par.-IMH}}(\vlambda) = \frac{1}{N} \sum_{i=1}^N s\,(\vz_{t}^{(i)}; \vlambda)
\end{align}
%
where \(\vz_{t-1}^{(i)}\) is the state of the \(i\)th chain at the previous SGD step.
Computationally speaking, we are still applying \(K\big(\vz_{t-1}^{(i)}\big)\) \(N\) times in total, so the cost is similar to the sequential state estimator.
However, the Markov-chain are \(N\) times shorter, which, in a traditional MCMC view, might seem to result in worse statistical performance.
An illustration of the parallel state estimator is shown in~\cref{fig:par}

%
\input{table_cost}
%
\paragraph{Computational Cost}
The three scheme using the CIS kernel and the IMH kernel can have different computational cost depending on the parameter \(N\).
The computational costs of each scemes are organized in~\cref{table:cost}.
In the CIS kernel, \(N\) controls the number of internal proposals sampled from \(q_{\vlambda}(\vz)\).
In the sequential and parallel state estimators, the IMH kernel only uses a single sample from \(q_{\vlambda}(\vz)\), but applies the kernel \(N\) times.
When estimating the score, the single state estimator computes \(\nabla_{\vlambda} q_{\vlambda}(\vz)\) only once, while for the sequential and parallel state estimators compute it \(N\) times.
However,~\cite{NEURIPS2020_b2070693} also discuss a Rao-Blackwellized version of the CIS kernel, which also computes the gradient \(N\) times.

\subsection{Theoretical Analysis}

\textcolor{red}{
  \paragraph{Boundedness Assumption}
Since we derive our bounds on the bias from the total-variation distance, our results assume that the score function is bounded.
That is, \(\norm{\nabla_{\vlambda} \log q_{\vlambda}(\vz)} < L\) for any \(\vlambda\).
This boundedness assumption is reasonable since theoretical guarentees of SGD often assume Lipschitz-continuity of the gradients, from which boundedness follow as a consequence.
}

\input{bias_seq}
%
For the sequential mode estimator, the bias depends on both \(t\) and \(N\).
Thus, the bias decreases as the number iteration \(t\) and the number of samples \(N\) increase.
However, the following proposition suggests that the \(w^*\) will be exponentially large when the KL divergence is large.
%
\begin{proposition}
  \(w^* = \sup_{\vz} \nicefrac{p\left(\vz\mid\vx\right)}{q_{\vlambda}\left(\vz\right)} \) is bounded below expoentially by the KL divergence such that
  \(
  \exp\left(\DKL{p\left(\cdot\mid\vx\right)}{ q_{\vlambda}\left(\cdot\right) }\right) \leq w^*.
  \)
  \begin{proof}
    \(
    \DKL{p\left(\cdot\mid\vx\right)}{ q_{\vlambda}\left(\cdot\right) }
    = \int p\left(\vz\mid\vx\right) \log \frac{p\left(\vz\mid\vx\right)}{q_{\vlambda}\left(\vz\right)}\,d\vz
    \leq \int p\left(\vz\mid\vx\right) \log M \, d\vz = \log w^*
    \)
  \end{proof}
\end{proposition}
%
Therefore, in the initial iterations of VI when the KL divergence has yet been minimized, the constant \(C\) will be close to 1.
On the other hand, when \(C\) is small, the bias will be small regardless of \(N\) and \(t\).
Thus, increasing \(N\) wouldn't result in significant bias reduction.

\input{bias_par}
\input{var_seq}

\subsection{Interpreting Conditional Importance Sampling as Independent Metropolis-Hastings}\label{section:cis_imh}
Many popular MCMC kernels are based on the Metropolis-Hastings test where a random proposal \(\vz^*\) is either accepted into the Markov-chain (\(\vz_{t} = \vz^*\)) or rejected (\(\vz_t = \vz_{t-1}\)).
Among these, independent Metropolis-Hastings (IMH) kernels generate proposals independently of \(\vz_{t-1}\) such as \(\vz^* \sim q\,(\vz)\) instead of \(\vz^* \sim q\,(\vz\mid\vz_{t-1})\).% for \textit{state-dependent}.
%This constrasts with other kernels that generate  proposals such as .
We show that the CIS kernel proposed by~\citet{NEURIPS2020_b2070693} turns out to be a type of IMH kernel that uses Barker's acceptance ratio~\citep{barker_monte_1965} for the Metropolis-Hastings test.
This interpretation enables the analysis of the \textit{rejection rate} of the CIS kernel.

\vspace{-0.1in}
\paragraph{Conditional Importance Sampling}
A pseudocode of the CIS kernel is shown in~\cref{alg:cis}.
The original algorithmic description of CIS is to
\begin{enumerate*}[label=(\roman*)]
  \item obtain \(N\) samples from \(q_{\vlambda}(\vz)\),
  \item compute the importance weight including the previous Markov-chain state \(\vz_{t-1}\), and 
  \item resample \(\vz_{t-1}\) from the multinomial distribution of \(N+1\) proposals.
\end{enumerate*}
%
While particle MCMC~\citep{andrieu_particle_2010} originally inspired the CIS kernel, it is possible to find connections in multiple-try MCMC methods~\citep{martino_review_2018}.
In particular, the CIS kernel is identical to the previously proposed \textit{ensemble MCMC sampler}~\citep{austad_parallel_2007, neal_mcmc_2011a} with independent proposals, which is an instance of multiple-try MCMC~\citep[Table 12]{martino_review_2018}.

\vspace{-0.1in}
\paragraph{CIS as a Metropolis-Hastings Kernel}
Now we show that the CIS kernel is an accept-reject type kernel with Barker's acceptance ratio.
First, by defining \(\vz_t = \vz_{t-1}\) as ``reject'' and \(\vz_t \neq \vz_{t-1}\) as ``accept'', the CIS kernel can be understood as an accept-reject type kernel.
By denoting the \(N\) parallel proposals as an \textit{ensemble state} \(\vz^{(1:N)} = (\vz^{(1)}, \ldots, \vz^{(N)})\)~\citep{neal_mcmc_2011a}, the CIS kernel conditional estimate can be written as
%
{%\small
  \begin{align}
    \Esub{K(\vz_{t-1}, \vz_t)}{f(\vz_t)\mid\vz_{t-1}}  = 
    \Esub{q_{\vlambda}}{
      \alpha\,(\vz_{t-1}, \vz^{(1:N)}) \,
      \frac{
        \sum^{N}_{i=1} w\,(\vz^{(i)})\,f(\vz^{(i)})
      }
           {
             \sum^{N}_{i=1} w\,(\vz^{(i)})
           }
    }
    + r\,(\vz_{t-1}) \, f(\vz_{t-1})\label{eq:cis_kernel}
  \end{align}
}
where \(q_{\vlambda}(\vz^{(1:N)}) = \prod^N_{i=1} q_{\vlambda}(\vz^{(i)}) \),
the acceptance ratio
\(
  \alpha(\vz_{t-1}, \vz^{(1:N)})
  = \nicefrac{\sum^{N}_{i=1} w\,(\vz^{(i)})}{\sum^{N}_{i=0} w\,(\vz^{(i)})}
\)
is the probability of accepting the ensemble state \(\vz^{(1:N)}\), and
\begin{align}
  r\,(\vz_{t-1}) = \Esub{q_{\vlambda}(\vz^{(1:N)})}{
    r\,(\vz_{t-1} \mid \vz^{(1:N)})
  }
  = \Esub{q_{\vlambda}(\vz^{(1:N)})}{
    \left(1 - \alpha\,(\vz_{t-1}, \vz^{(1:N)})\right)
  }
\end{align}
is the probability of staying on \(\vz_{t-1}\) by rejecting \textit{any} ensemble state, \(r\,(\vz_{t-1}\mid \vz^{(1:N)})\) is the rejection rate given \(\vz^{(1:N)}\).
The expression of \(\alpha\,(\vz_{t-1}, \vz^{(1:N)})\) is known as Barker's acceptance ratio~\citep{barker_monte_1965}, which is a special case of the original Metropolis ratio~\citep{metropolis_equation_1953}.
(A detailed derivation is in the \textit{supplementary material}.)

%% Now, the transition kernel can be denoted as
%% \begin{align}
%%   K(\vz_{t-1}, \vz) = \int K(\vz^{(1:N)}, \vz) \, \big( 1 - r\,(\vz_{t-1}\mid\vz^{(1:N)}) \big) \, q_{\vlambda}( \vz^{(1:N)} ) \, d\vz^{(1:N)}
%%   + r\,(\vz_{t-1}) \,\delta_{\vz_{t-1}}(\vz)
%% \end{align}

\subsection{Bias-Variance Tradeoff of Conditional Importance Sampling}\label{section:bias_variance}
\paragraph{Variance of Conditional Importance Sampling}
The IMH (or accept-reject) view in~\cref{section:cis_imh} now enables us to discuss the rejection rate of the CIS kernel.
As discussed in~\cref{section:msc_mcmc}, MSC obtains gradients using the conditional estimates of MCMC.
The variance of the conditional estimate is closely related to the rejection rate such as
\begin{align}
  \Vsub{K(\vz_{t-1},\cdot)}{f \mid \vz_{t-1}} 
  &=\Vsub{q_{\vlambda}}{ \E{ f \mid \vz_{t-1},\,\vz^{(1:N)} } } + \underbrace{\Esub{q_{\vlambda}}{ \V{ f \mid \vz_{t-1},\,\vz^{(1:N)} } }}_{\text{Rao-Blackwellization gain}} \label{eq:total_variance} \\
  &\geq \Vsub{q_{\vlambda}}{ \E{ f \mid \vz_{t-1},\,\vz^{(1:N)} } } \label{eq:rao_blackwell}\\
  &= \Vsub{q_{\vlambda}}{ \big(1 - r\,(\vz_{t-1}\mid\vz^{(1:N)})\big)\, f_{\mathrm{IS}}
    + r\,(\vz_{t-1}\mid\vz^{(1:N)})\,f(\vz_{t-1}) \;\middle\vert\; \vz_{t-1} } \label{eq:exact_variance} \\
  &\text{where}\;\; f_{\mathrm{IS}} = {\sum_{i=1}^N w\,(\vz^{(i)}) f(\vz^{(i)})\,/\,\sum_{i=1}^N w\,(\vz^{(i)})}. \nonumber 
\end{align}
%
The bound in~\eqref{eq:rao_blackwell} becomes exact if we use Rao-Blackwellization (that is, if we use the SNIS estimator \(\sum^{N}_{i=1} \widetilde{w}^{(i)}\,f\,(\vz^{(i)})\) instead of the resampled \(\vz_t\)) as mentioned by~\citet{NEURIPS2020_b2070693}.
The expansion in~\eqref{eq:total_variance} follows from the law of total variance where the right-hand term is the variance reduction we gain from using Rao-Blackwellization~\citep{bernton_locally_2015}, and the equality in~\eqref{eq:exact_variance} follows from~\eqref{eq:cis_kernel}.

\vspace{-0.1in}
\paragraph{Low rejection rate means high conditional variance.}
Because of the dependence of \(r\,(\vz_{t-1}\mid\vz^{(1:N)})\) on \(\vz^{(1:N)}\), it is in general difficult to interpret the result of~\eqref{eq:exact_variance}.
Nonetheless, when \(w\,(\vz_{t-1}) \gg w\,(\vz^{(i)})\), \(r(\vz\mid\vz^{(1:N)})\) is close to 1 almost independently of \(q_{\vlambda}(\vz)\).
The intuition is that if the \textit{rejection weight} \(w\,(\vz_{t-1})\) is large, most proposals will be rejected regardless of their values.
By translating this intuition into an approximation, we obtain the following result.
%
\input{variance_approx}
%
The statement of~\cref{thm:approx_var} is intuitive; if we reject all the states, there is no conditional variance.
However, this obvious fact becomes more interesting combined with the followings.

\vspace{-0.1in}
\paragraph{CIS has a high rejection rate until MSC converges.}
The following bound provides a condition for the rejection rate of a CIS kernel to be high.
%
\input{cis_bound}
%
When \(w\,(\vz_{t-1})\) is large, the lower bound of \(r(\vz_{t-1})\) becomes close to one.
In this case, according to~\cref{thm:approx_var}, the conditional variance becomes minimal.

In the context of VI, the following shows that \(r\,(\vz_{t-1})\) is huge when the KL divergence is large.
%
\input{cis_bound_kl}
%
This result states that in the ideal case when the Markov-chain has achieved stationarity and \(\vz_{t-1}\) closely follows \(p\,(\vz\mid\vx)\), the average rejection weight is bounded below exponentially by the KL divergence.
The bound is tight as long as \(\DKL{p}{q_{\vlambda}}\) is large.
In practical conditions, the rejection rate cannot be improved by increasing \(N\) since
\begin{enumerate*}[label=(\roman*)]
  \item the iteration complexity also increases, and
  \item \(w\,(\vz_t)\) can easily be larger by many orders of magnitude.
\end{enumerate*}

The results of \cref{thm:cis_bound_kl} signify that, until MSC converges such that \(\DKL{p}{q_{\vlambda}}\) is small, the rejection rate will be very high.
And by~\cref{thm:approx_var}, the variance will be small, improving the convergence of SGD.
This explains why the Markov-chain in~\cref{fig:motivating} does not move until MSC converges and why MSC works well with the CIS kernel.
Note that these properties hold similarly in any IMH type kernels.


\vspace{-0.1in}
\paragraph{Is bias guaranteed to decrease?}
The bias of the conditional estimate is closely related to the total variation (TV) distance \(\DTV{K(\vz_{t-1}, \cdot)}{p(\cdot\mid\vx)}\).
For bounded functions, the TV distance provides an upper bound of the bias.
Unfortunately, it is in general difficult to specify the TV distance (and hence the bias) with respect to \(p\,(\vz\mid\vx)\) and \(q_{\vlambda}(\vz)\).
Neverthless,~\citet{wang_exact_2020} recently showed that the rejection rate is related with the TV distance such that \(r\,(\vz_{t-1}) \leq \DTV{K(\vz_{t-1}, \cdot)}{p\,(\cdot\mid\vx)}\).
Therefore, a low rejection rate is \textit{necessary} for the bias to decrease.

\vspace{-0.1in}
\paragraph{Automatic Bias-Variance Tradeoff of IMH Type Kernels}
To summarize, IMH type kernels (including the CIS kernel) have an automatic bias-variance tradeoff mechanism.
In the initial steps where the inclusive KL divergence is large, variance is suppressed by rejecting most proposals.
However, as MSC converges, the bound on the rejection rate becomes loose, admitting a lower rejection rate, which enables bias to decrease.
This mechanism provides an interesting case where rejections in MCMC can actually be beneficial.
Lastly, we note that the automatic tradeoff mechanism is a unique property of IMH type kernels; it does not exist in kernels with state-dependent proposals such as random-walk Metropolis-Hastings or HMC.

%% that the KL divergence is related to the maximum importance ratio \(w^* = \sup_{\vz} p(\vz\mid\vx) / q_{\vlambda}(\vz)\) such that
%% \begin{align}
%%   \DKL{p}{q_{\vlambda}} = \int p(\vz\mid\vx) \log \frac{p(\vz\mid\vx)}{q_{\vlambda}(\vz)} d\vz < \int p(\vz\mid\vx)  \log w^* d\vz = \log w^*.
%% \end{align}
%% \(\DKL{p}{q_{\vlambda}} < \infty\) is thus a necessary condition for \(w < \infty\) which is required for \(K\) to be geometrically ergodic~\citep{wang_exact_2020}.
%% Also, 

%% the TV distance is bounded 
%% This implies 
%% This is not only 
%As shown by~\citet{10.1214/17-STS611, chatterjee_sample_2018}, the number of particles for acheiving bounded error reduces exponentially with the KL divergence.

%% \subsection{Reducing Variance with Parallel Independent Metropolis-Hastings Markov-Chains}\label{section:cis_bias}
%% Recall that the CIS kernel uses \(N\) multiple-try type proposals.
%% Thus, it is natural to expect the variance to decrease as the (per-transition) computational budget \(N\) increases.
%% However, under specific conditions, we find that the variance actually \textit{increases} with \(N\).

%% \vspace{-0.1in}
%% \paragraph{The variance of CIS can increase with \(N\).}
%% The bound in~\cref{thm:cis_bound} can be reinterpreted as a bound on the acceptance rate 
%% \begin{align}
%%   1 - r\,(\vz_{t-1}) \leq \frac{N\,Z}{ w\,(\vz_{t-1}) + N\,Z}\;,
%% \end{align}
%% which is, in general, very tight.
%% More importantly, when \(w\,(\vz_{t-1}) \gg N\,Z\), the acceptance rate grows like \(\mathcal{O}(N)\).
%% On the other hand, the variance of an SNIS estimator is known to decrease approximately at a rate of \(\mathcal{O}(1/N)\)~\citep{kong_sequential_1994, robert_monte_2004, elvira_rethinking_2018}.
%% That is, 
%% \begin{align}
%%   \Vsub{q_{\vlambda}}{ \E{ f \mid \vz_{t-1},\,\vz^{(1:N)} } } \approx \underbrace{{\big(1 - r\,(\vz_{t-1})\big)}^2}_{\text{approx.}\;\;\mathcal{O}(N^2)} \,
%%   \underbrace{\Vsub{q_{\vlambda}}{ f_{\text{IS}} }}_{\text{approx.}\;\;\mathcal{O}(1/N)}.\label{eq:cis_variance_incr}
%% \end{align}
%% Thus, when \(w\,(\vz_{t-1})\gg N\,Z\), the conditional variance of CIS approximately grows as \(\mathcal{O}(N)\).
%% We provide numerical simulations that support our analysis in the \textit{supplementary material}.

%% \vspace{-0.02in}
%% \input{pimh_algorithm}

%% \vspace{-0.1in}
%% \paragraph{Variance Reduction with Paralel IMH Chains}
%% To resolve the aforementioned limitation of the CIS kernel, we propose a simple but effective remedy: running \(N\) parallel IMH (PIMH) Markov-chains \( \big\{\,\vz_t^{(1)}\big\}, \big\{\,\vz_t^{(2)}\big\}, \ldots, \big\{\,\vz_t^{(N)}\big\}\) where each of the chains performs a Metropolis-Hastings test with only a \textit{single} proposal each.
%% The modified MSC algorithm incorporating parallel chains is shown in~\cref{alg:pimh} (the modified parts are highlighted in \textcolor{blue}{blue} and \textcolor{purple}{purple}), while the IMH kernel is described in~\cref{alg:imh}.
%% Since the parallel chains generate an \textit{independent} conditional estimate each, the gradient estimate \(\nicefrac{1}{N} \sum^{N}_{i=1} s\,(\vz_t^{(i)}; \vlambda)\) is an average of \(N\) independent and identical estimators.
%% This obviously reduces the variance of a single conditional estimate as \(\mathcal{O}(1/N)\).
%% In the best case, relative to CIS, PIMH will have a variance reduction close to \(\mathcal{O}(1/N^2)\).
%% %Also, the estimates are now proper marginal esimates, which enjoy a tighter bound on the TV distance (and hence the bias).
%% %
%% %\input{bias_reduction}

%% \vspace{-0.1in}
%% \paragraph{Lower bound of rejection rate in IMH}
%% IMH also enjoys variance control properties similar to the CIS kernel.
%% That is, a lower bound similar to~\cref{thm:cis_bound} can be shown.
%% %
%% \input{imh_bound}
%% %
%% Unlike CIS, we can see that the bound does not depend on \(N\).
%% This means the rejection rate will \textit{not} prematurely increase.
%% We thus obtain all the benefits of CIS except its limitations.
%% %Using~\cref{thm:imh_bound}, a similar result to~\cref{thm:cis_bound_kl} can be obtained.

%% \vspace{-0.1in}
%% \paragraph{Costs and Limitation of PIMH}
%% The computational cost of sampling \(\vz^{(i)}_{t}\) (\textcolor{blue}{blue} region in \cref{alg:pimh}) for \(N\) chains is equal to a CIS kernel with \(N\) proposals.
%% On the other hand, the cost of estimating the stochastic gradient (\textcolor{purple}{purple} region in \cref{alg:pimh}) is now \(\mathcal{O}(N)\) instead of \(\mathcal{O}(1)\) of the CIS kernel.
%% This cost is, however, also imposed on the CIS kernel if we use Rao-Blackwellization.
%% Thus, the overall computational cost of PIMH is more or less equal to that of the CIS kernel.
%% The only downside of PIMH is that the Metropolis-Hastings acceptance ratio that we use has a slightly larger acceptance rate than Barker's~\citep{peskun_optimum_1973, minh_understanding_2015}.
%% In the small \(N\) regime, PIMH has a slightly larger conditional variance, but it can be easily fixed by using Barker's ratio.

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
