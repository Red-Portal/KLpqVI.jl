
\section{Introduction}
Given an observed data \(\vx\) and a latent variable \(\vz\), Bayesian inference aims to analyze \(p\,(\vz\,|\,\vx)\) given an unnormalized joint density \(p\,(\vz,\,\vx)\) where the relationship is given by Bayes' rule such that \(p\,(\vz\,|\,\vx) = {p\,(\vz,\,\vx)}/{p\,(\vx)} \propto p\,(\vz,\,\vx)\).
Instead of working directly with the target distribution \(p\,(\vz\,|\,\vx)\), variational inference (VI,~\citealt{jordan_introduction_1999, blei_variational_2017, zhang_advances_2019}) searches for a variational approximation \(q_{\lambda}(\vz)\) that is similar to \(p\,(\vz\,|\,\vx)\) according to a discrepancy measure \(D\,(p,\, q_{\vlambda})\).

Naturally, choosing a good discrepancy measure, or objective function, is a critical part of the problem.
This fact had lead to a quest for good divergence measures~\citep{NIPS2016_7750ca35, NIPS2017_35464c84, NEURIPS2018_1cd138d0, pmlr-v97-ruiz19a}.
So far, the exclusive KL divergence \(\DKL{q_{\lambda}}{p}\) (or reverse KL divergence) has been used ``exclusively'' among various discrepancy measures.
This is partly because the exclusive KL is defined as an average over \(q_{\lambda}(\vz)\), which can be estimated efficiently.
By contrast, the inclusive KL is defined as
%
%\vspace{-0.02in}
\begin{align}
  %% \DKL{p}{q_{\lambda}} = \int p\,(\vz\mid\vx) \log\big(\, p\,(\vz\mid\vx)/q_{\lambda}(\vz) \,\big)\,d\vz
  %% = \Esub{p(\vz\mid\vx)}{\log\big(\, p\,(\vz\mid\vx)/q_{\lambda}(\vz) \,\big) } \label{eq:klpq}
  \DKL{p}{q_{\lambda}}
  &= \int p\,(\vz\mid\vx) \log \frac{p\,(\vz\mid\vx)\,}{\,q_{\lambda}(\vz)} \,d\vz \\
  &= \Esub{p(\vz\mid\vx)}{\log \frac{p\,(\vz\mid\vx)\,}{\,q_{\lambda}(\vz)} } \label{eq:klpq}
\end{align}
%\vspace{-0.02in}
%
\noindent where the average is taken over \(p\,(\vz\,|\,\vx)\). 
Interestingly, this is a chicken-and-egg problem as our goal is to obtain \(p\,(\vz\,|\,\vx)\) in the first place.
Despite this challenge, minimizing~\eqref{eq:klpq} has drawn the attention of researchers because it is believed to result in favorable statistical properties~\citep{minka2005divergence, mackay_local_2001}.

For performing inclusive VI,~\citet{NEURIPS2020_b2070693} and~\citet{pmlr-v124-ou20a} have recently proposed  methods that perform stochastic gradient descent (SGD,~\citealt{robbins_stochastic_1951}) with the score gradient estimated using Markov-chain Monte Carlo (MCMC).
These MCMC score climbing schemes operate a (or multiple) Markov-chain in conjuction with the VI optimizer.
In addition, within the MCMC kernel, they both use Metropolis-Hastings proposals generated from the variational approximation \(\vz^* \sim q_{\vlambda}\left(\cdot\right)\).
Therefore, the MCMC kernel itself benefits from the variational inference process, gradually improving over time.
This enables the MCMC kernel to be sufficiently efficient without the need of computationally expensive kernel such as Hamiltonian Monte Carlo~\citep{duane_hybrid_1987, neal_mcmc_2011, betancourt_conceptual_2017}.

While the methods by~\citeauthor{NEURIPS2020_b2070693} and~\citeauthor{pmlr-v124-ou20a} are conceptually similar, they use their MCMC kernels in slightly different ways.
At each SGD iteration, for estimating the score function, \citeauthor{NEURIPS2020_b2070693} use a single state of the Markov-chain generated from a computationally expensive MCMC kernel.
On the other hand, given a similar computational budget,~\citeauthor{pmlr-v124-ou20a} use \(N\) states generated from a cheaper MCMC kernel.
We call the former option the \(single state estimator\) and the later the \(sequential state estimator\)
It is now natural to ask, ``which is better? An estimator with multiple cheap samples? or one with a single expensive sample?''.

Furthermore, a third, but seldomly mentioned option exist.
We call this the setup \textit{the parallel state estimator}.
For this estimator, we operate \(N\) parallel Markov-chains parallel, where only a single state transition is performed on each chain.
The variance of this estimator dramatically benefits from increasing the computational budget compared to the single and sequential state estimators.
While this comes at the cost of slightly higher bias, we observe that the variance reduction is significant enough.

In this work, we compare the bias and variance of the three different schemes of using an MCMC kernel for score climbing variational inference.
We discuss the bias and variance of the three schemes, and conduct experiments on general Bayesian inference benchmarks.
Our results show that, given a similar number of computational budget \(N\), the parallel state estimator results in the best performance.
Also compared to exclusive KL divergence minimization methods such as automatic differentiation VI, score climbing VI is much more efficient since we do not need to differentiate through the likelihood.

%% generated by the conditional importance sampling (CIS,~\citealt{NEURIPS2020_b2070693, andrieu_particle_2010, andrieu_uniform_2018}) kernel, which uses \(N\) samples from \(q_{\vlambda}(\cdot)\) per transition.
%% \citeauthor{pmlr-v124-ou20a}, on the other hand, use multiple sequentially generated states from independent Metropolis-Hastings (IMH,~\citealt[Algorithm 25]{hastings_monte_1970}), which only uses 1 sample from \(q_{\vlambda}(\cdot)\).
%% Therfore, \citeauthor{pmlr-v124-ou20a} use multiple cheaply generated samples, while \citeauthor{NEURIPS2020_b2070693} use a single expensively generated samples.

%Finally, some interesting connections with adaptive MCMC methods~\citep{10.1007/s11222-008-9110-y} are discussed.

\paragraph{Contribution Summary}
\vspace{-0.1in}
\begin{itemize}
\item[\ding{228}] We propose the parallel state estimator for estimating the score function using MCMC (\textbf{\cref{section:overview}}).
\vspace{-0.1in}
\item[\ding{228}] We discuss the bias and variance of the MCMC score estimation schemes (\textbf{\cref{section:theory}}).
\vspace{-0.1in}
\item[\ding{228}] We experimentally compare the VI performance of the considered MCMC estimation schemes on general Bayesian inference benchmark problems (\textbf{\cref{section:eval}}).
\end{itemize}
%\item We discuss connections with adaptive IMH methods (\textbf{\cref{section:related}}).
%\end{enumerate*}

%%% Local Variables:
%%% TeX-master: "master"
%%% End:
